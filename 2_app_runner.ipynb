{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ragyeongyoon/audit-case-solver/blob/main/2_app_runner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
      ],
      "metadata": {
        "id": "KrkA_QqioZro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Streamlit, LangChain ë“± ì•± ì‹¤í–‰ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "!pip install streamlit pyngrok langchain-core langchain langchain_openai langchain_community tiktoken faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0NXVgjilF5z",
        "outputId": "29f2986b-c6a7-4b4e-82fa-4102a8a3c72c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.47.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.12)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.72)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.11/dist-packages (0.3.28)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0.post1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (0.4.8)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (2.11.7)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.97.1)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.12.14)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.48.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core) (3.11.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.7.14)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ê¸°ë³¸ ì„¤ì • (API í‚¤ ë° ë“œë¼ì´ë¸Œ ì—°ê²°)"
      ],
      "metadata": {
        "id": "Z8f_DrsUoddH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "sXfyhU7kSqBg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1b212a4-b2ea-4bbc-a99f-f74357458e26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "âœ… Colab ë³´ì•ˆ ë¹„ë°€ì—ì„œ API í‚¤ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.\n",
            "âœ… Streamlitìš© ë¹„ë°€ íŒŒì¼(secrets.toml) ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "#  ê¸°ë³¸ ì„¤ì • (ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸ ë° API í‚¤)\n",
        "import os\n",
        "from google.colab import drive\n",
        "from google.colab import userdata\n",
        "\n",
        "# êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# 1. Colab ë³´ì•ˆ ë¹„ë°€ì—ì„œ API í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
        "try:\n",
        "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "    print(\"âœ… Colab ë³´ì•ˆ ë¹„ë°€ì—ì„œ API í‚¤ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Colab ë³´ì•ˆ ë¹„ë°€ì—ì„œ API í‚¤ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}\")\n",
        "    # í‚¤ê°€ ì—†ìœ¼ë©´ ì•„ë˜ ì½”ë“œê°€ ì˜ë¯¸ ì—†ìœ¼ë¯€ë¡œ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\n",
        "    raise SystemExit(\"API í‚¤ë¥¼ ë¨¼ì € ì„¤ì •í•´ì£¼ì„¸ìš”.\")\n",
        "\n",
        "# 2. Streamlitì´ ì½ì„ ìˆ˜ ìˆë„ë¡ .streamlit í´ë”ì™€ secrets.toml íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "# ì´ ì‘ì—…ì€ Colab ë…¸íŠ¸ë¶ í™˜ê²½ì—ì„œ ìˆ˜í–‰ë©ë‹ˆë‹¤.\n",
        "!mkdir -p .streamlit\n",
        "with open(\".streamlit/secrets.toml\", \"w\") as f:\n",
        "    f.write(f'OPENAI_API_KEY = \"{OPENAI_API_KEY}\"')\n",
        "\n",
        "print(\"âœ… Streamlitìš© ë¹„ë°€ íŒŒì¼(secrets.toml) ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Streamlit ì•± ì½”ë“œ ì‘ì„± (app.py íŒŒì¼ ìƒì„±)"
      ],
      "metadata": {
        "id": "XELdkvLPlRvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import os\n",
        "import datetime\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# --- 1. API í‚¤ ì„¤ì • ---\n",
        "try:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = st.secrets[\"OPENAI_API_KEY\"]\n",
        "except KeyError:\n",
        "    st.error(\"OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .streamlit/secrets.toml íŒŒì¼ì´ ì˜¬ë°”ë¥´ê²Œ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
        "    st.stop()\n",
        "\n",
        "# --- 2. RAG ì²´ì¸ ë¡œë”© í•¨ìˆ˜ (ìºì‹œ ì‚¬ìš©) ---\n",
        "@st.cache_resource\n",
        "def load_rag_chain():\n",
        "    VECTOR_STORE_DIR = '/content/drive/MyDrive/RAG_Audit_Project/03_vector_store'\n",
        "    embeddings_model = OpenAIEmbeddings()\n",
        "    vectorstore = FAISS.load_local(\n",
        "        VECTOR_STORE_DIR,\n",
        "        embeddings_model,\n",
        "        allow_dangerous_deserialization=True\n",
        "    )\n",
        "    prompt_template = \"\"\"\n",
        "    <ì§€ì‹œë¬¸>\n",
        "    - ë‹¹ì‹ ì€ íšŒê³„ê°ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
        "    - <Context>ì™€ <ì§ˆë¬¸>ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.\n",
        "    - ë‹µë³€ì€ ë°˜ë“œì‹œ ì•„ë˜ <ë‹µë³€í˜•ì‹>ì„ ë”°ë¼ì•¼ í•˜ë©°, 'ë‹µë³€ ê·¼ê±°ë€', 'ê´€ë ¨ êµì¬ ë‚´ìš©' ê°™ì€ ë¬¸êµ¬ëŠ” ì ˆëŒ€ ì¶œë ¥í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤.\n",
        "    - '###' ê¸°í˜¸ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.\n",
        "    - í•œêµ­ì–´ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”\n",
        "    - ì•„ë˜ í”„ë¡¬í”„íŠ¸ì˜ ë‚´ìš©ì„ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš” ([Contextì—ì„œ ì°¾ì•„ë‚¸ êµ¬ì²´ì ì¸ ê¸°ì¤€ì´ë‚˜ ë¬¸êµ¬ë¥¼ ì¸ìš©í•©ë‹ˆë‹¤.] ë“±)\n",
        "    </ì§€ì‹œë¬¸>\n",
        "\n",
        "    <ë‹µë³€í˜•ì‹>\n",
        "    ### ì •ë‹µ:\n",
        "    - ì§ˆë¬¸ì— ëŒ€í•œ ëª…í™•í•œ ê²°ë¡ ì„ ë‚´ë¦½ë‹ˆë‹¤. ë¬¼ì–´ë³´ëŠ” ê²ƒì— ëŒ€í•´ ì§§ê²Œ ëŒ€ë‹µí•©ë‹ˆë‹¤\n",
        "    - ì—¬ë¶€ë¥¼ ë¬¼ì—ˆì„ ë•ŒëŠ” O/Xë¡œ ëŒ€ë‹µí•©ë‹ˆë‹¤.\n",
        "    - ì ì ˆí•œê°€? í•˜ê³  ë¬¼ì—ˆì„ ë•ŒëŠ” ì˜ˆ, ì•„ë‹ˆì˜¤ë¡œ ëŒ€ë‹µí•©ë‹ˆë‹¤.\n",
        "    - ì˜ëª»ëœ ê°ì‚¬ì ˆì°¨ë¥¼ ë¬¼ì—ˆì„ ë•ŒëŠ” ë³¸ë¬¸ì—ì„œ ì˜ëª»ëœ ê°ì‚¬ì ˆì°¨ ë‚´ìš©ì„ ì°¾ìŠµë‹ˆë‹¤.\n",
        "    - ìˆ˜í–‰í•˜ì—¬ì•¼ í•  ì ˆì°¨ë¥¼ ë¬¼ì—ˆì„ ë•ŒëŠ” êµ¬ì²´ì ì¸ ì‚¬ë¡€ë³´ë‹¤ëŠ” contextì—ì„œ ì ˆì°¨ ê´€ë ¨ëœ ì–¸ê¸‰ì´ ìˆì„ ê²½ìš° ê¸°ì¤€ì„œë¥¼ ìµœëŒ€í•œ ì¤€ìš©í•©ë‹ˆë‹¤.\n",
        "    - ëª‡ ê°€ì§€ë¥¼ ë¬¼ì–´ë³´ëŠ”ì§€ íŒŒì•…í•˜ê³  ì§ˆë¬¸ì— ë§ëŠ” ë‹µì•ˆì„ êµ¬ì„±í•©ë‹ˆë‹¤. (2ê°€ì§€ë¥¼ ë¬¼ì—ˆì„ ê²½ìš° 2ê°€ì§€ë¡œ ëŒ€ë‹µí•©ë‹ˆë‹¤. ì²«ì§¸ ì‚¬í•­/ì ˆì°¨(ë¬¼ìŒì—ì„œ ë¬¼ì–´ë³¸ê²ƒ)ëŠ”, ë‘˜ì§¸ ì‚¬í•­/ì ˆì°¨(ë¬¼ìŒì—ì„œ ë¬¼ì–´ë³¸ê²ƒ)ëŠ”, ì´ëŸ° ì‹ìœ¼ë¡œ ëŒ€ë‹µí•©ë‹ˆë‹¤.)\n",
        "\n",
        "    ### íŒë‹¨ ê·¼ê±°:\n",
        "    - [Contextì—ì„œ ì°¾ì•„ë‚¸ êµ¬ì²´ì ì¸ ê¸°ì¤€ì´ë‚˜ ë¬¸êµ¬ë¥¼ ì¸ìš©í•©ë‹ˆë‹¤.]\n",
        "    - ìµœëŒ€í•œ ê°ì‚¬ê¸°ì¤€ì„œë‚˜ ì ˆì°¨ëŠ” ì œê³µëœ contextì˜ ìš©ì–´ì™€ í‘œí˜„ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "    - ì‚¬ë¡€ì—ì„œ ì œê³µëœ ë¬¸ì œì ì„ ì§€ì í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "    - ë‹¤ë§Œ, contextì˜ íšŒê³„ê°ì‚¬ê¸°ì¤€, ìœ¤ë¦¬ê¸°ì¤€ ë“± ë‹¤ì–‘í•œ ë‚´ìš©ì„ ê·¼ê±°ë¡œ ìœ„ë°°ëœ ë¶€ë¶„ì´ ìˆëŠ”ì§€ íŒŒì•…í•©ë‹ˆë‹¤.\n",
        "    - ì œê³µëœ ì§ˆë¬¸ì—ì„œ ì˜ëª»ëœ ë¶€ë¶„ì„, contextë¥¼ ê·¼ê±°ë¡œ í‰ê°€í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "    - ë‹¹ì‹ ì€ 30ë…„ ì´ìƒì˜ ìˆ™ë ¨ëœ íšŒê³„ì‚¬ë¡œ, ëª¨ë“  íšŒê³„ê°ì‚¬ê¸°ì¤€ì„ ëª…ë°±íˆ ì´í•´í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
        "    - ë‹¹ì‹ ì—ê²Œ ì œì‹œëœ ì§ˆë¬¸ì˜ textì—ì„œ ê°ì‚¬ì ˆì°¨ê°€ ì ì ˆ/ë¶€ì ì ˆí•œì§€ íŒë‹¨í•œ ì´ìœ ë¥¼ ê·¼ê±°ë¥¼ ë“¤ì–´ ë§í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "    ---\n",
        "    Context:\n",
        "    {context}\n",
        "\n",
        "    Question:\n",
        "    {question}\n",
        "\n",
        "    Answer(Korean):\n",
        "    \"\"\"\n",
        "    PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "    llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
        "    rag_chain = RetrievalQA.from_chain_type(\n",
        "        llm=llm, chain_type=\"stuff\", retriever=vectorstore.as_retriever(search_kwargs={'k': 5}),\n",
        "        chain_type_kwargs={\"prompt\": PROMPT}, return_source_documents=True\n",
        "    )\n",
        "    return rag_chain\n",
        "\n",
        "# --- 3. ëŒ€í™” ë‚´ìš©ì„ HTMLë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ ---\n",
        "def generate_html(history):\n",
        "    timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "    html_content = f\"\"\"\n",
        "    <!DOCTYPE html><html><head><title>íšŒê³„ê°ì‚¬ AI ëŒ€í™” ê¸°ë¡</title>\n",
        "    <style>\n",
        "        body {{ font-family: sans-serif; line-height: 1.6; padding: 20px; }}\n",
        "        .container {{ max-width: 800px; margin: auto; border: 1px solid #ddd; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}\n",
        "        .qa-pair {{ border-bottom: 2px solid #eee; padding-bottom: 20px; margin-bottom: 20px; }}\n",
        "        .question-block {{ background-color: #e1f5fe; padding: 15px; border-radius: 8px; margin-bottom: 10px; border-left: 5px solid #0288d1; }}\n",
        "        .answer-block {{ background-color: #f1f8e9; padding: 15px; border-radius: 8px; margin-bottom: 20px; border-left: 5px solid #7cb342;}}\n",
        "        h1, h2, h3 {{ color: #0277bd; }}\n",
        "        h1 {{ text-align: center; }}\n",
        "        .timestamp {{ text-align: right; color: #757575; font-size: 0.9em; }}\n",
        "        .save-timestamp {{ text-align: center; color: #757575; margin-bottom: 20px; }}\n",
        "        pre {{ white-space: pre-wrap; word-wrap: break-word; font-size: 14px; }}\n",
        "    </style></head><body><div class=\"container\">\n",
        "        <h1>íšŒê³„ê°ì‚¬ AI ëŒ€í™” ê¸°ë¡</h1>\n",
        "        <p class=\"save-timestamp\">ì €ì¥ ì‹œê°: {save_timestamp}</p>\n",
        "    \"\"\"\n",
        "    for item in history:\n",
        "        # Markdownì„ HTML ì¤„ë°”ê¿ˆìœ¼ë¡œ ë³€ê²½\n",
        "        formatted_result = item['result'].replace('\\n', '<br>')\n",
        "        # ì§ˆë¬¸ ì‹œê°„ì„ HTMLì— ì¶”ê°€\n",
        "        query_timestamp = item['timestamp'].strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        html_content += f\"\"\"\n",
        "        <div class=\"qa-pair\">\n",
        "            <p class=\"timestamp\">ì§ˆë¬¸ ì‹œê°: {query_timestamp}</p>\n",
        "            <div class='question-block'>\n",
        "                <h3>ì§ˆë¬¸</h3>\n",
        "                <pre>{item['query']}</pre>\n",
        "            </div>\n",
        "            <div class='answer-block'>\n",
        "                <h3>AI ë‹µë³€</h3>\n",
        "                {formatted_result}\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "    html_content += \"</div></body></html>\"\n",
        "    return html_content\n",
        "\n",
        "# --- 4. Streamlit ì›¹ UI êµ¬ì„± ---\n",
        "st.set_page_config(page_title=\"íšŒê³„ê°ì‚¬ RAG AI\", layout=\"wide\")\n",
        "st.title(\"ğŸ¤– íšŒê³„ê°ì‚¬ ë¬¸ì œí’€ì´ AI ì–´ì‹œìŠ¤í„´íŠ¸\")\n",
        "\n",
        "# --- st.session_state ì´ˆê¸°í™” ---\n",
        "# 'history': ëŒ€í™” ê¸°ë¡ ì €ì¥\n",
        "# 'show_history': ëŒ€í™” ê¸°ë¡ ë³´ê¸°/ìˆ¨ê¸°ê¸° ìƒíƒœ ì €ì¥\n",
        "if 'history' not in st.session_state:\n",
        "    st.session_state.history = []\n",
        "if 'show_history' not in st.session_state:\n",
        "    st.session_state.show_history = False\n",
        "\n",
        "# --- ì‚¬ì´ë“œë°” UI ---\n",
        "with st.sidebar:\n",
        "    st.header(\"ë©”ë‰´\")\n",
        "\n",
        "    # 1. ëŒ€í™” ê¸°ë¡ ë³´ê¸° ë²„íŠ¼ (ìƒíƒœ í† ê¸€)\n",
        "    if st.button(\"ëŒ€í™” ê¸°ë¡ ë³´ê¸°/ìˆ¨ê¸°ê¸°\"):\n",
        "        st.session_state.show_history = not st.session_state.show_history\n",
        "\n",
        "    # 2. ëŒ€í™” ê¸°ë¡ ì €ì¥ ë²„íŠ¼\n",
        "    if st.session_state.history:\n",
        "        html_str = generate_html(st.session_state.history)\n",
        "        file_name = f\"audit_conversation_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.html\"\n",
        "        st.download_button(\n",
        "            label=\"ëŒ€í™” ë‚´ìš© HTMLë¡œ ì €ì¥\",\n",
        "            data=html_str.encode('utf-8'),\n",
        "            file_name=file_name,\n",
        "            mime='text/html'\n",
        "        )\n",
        "\n",
        "    # 3. ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” ë²„íŠ¼\n",
        "    if st.button(\"ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”\"):\n",
        "        st.session_state.history = []\n",
        "        st.session_state.show_history = False # ê¸°ë¡ ì´ˆê¸°í™” ì‹œ ë³´ê¸° ìƒíƒœë„ ì´ˆê¸°í™”\n",
        "        st.success(\"ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "\n",
        "# --- ë©”ì¸ í™”ë©´ UI ---\n",
        "try:\n",
        "    rag_chain = load_rag_chain()\n",
        "\n",
        "    st.caption(\"íšŒê³„ê°ì‚¬ ì‹œí—˜ ë¬¸ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”\")\n",
        "    # ì…ë ¥ë€ 2ê°œë¡œ ë¶„ë¦¬\n",
        "    # st.markdownì„ ì‚¬ìš©í•˜ì—¬ ì›í•˜ëŠ” í¬ê¸°ì˜ ì œëª©ì„ í‘œì‹œí•©ë‹ˆë‹¤.\n",
        "    st.markdown(\"### ë¬¸ì œ\")\n",
        "    # ê¸°ì¡´ text_areaì˜ labelì€ ìˆ¨ê¹ë‹ˆë‹¤ (label_visibility=\"collapsed\").\n",
        "    problem_context = st.text_area(\n",
        "        \"problem_input_area\", # ìœ„ì ¯ì„ êµ¬ë¶„í•˜ê¸° ìœ„í•œ ê³ ìœ  í‚¤\n",
        "        height=150,\n",
        "        placeholder=\"ì—¬ê¸°ì— ë¬¸ì œ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”\",\n",
        "        label_visibility=\"collapsed\"\n",
        "    )\n",
        "\n",
        "    # ë‘ ë²ˆì§¸ ì…ë ¥ì°½ë„ ë™ì¼í•˜ê²Œ ìˆ˜ì •í•©ë‹ˆë‹¤.\n",
        "    st.markdown(\"### ë¬¼ìŒ\")\n",
        "    specific_question = st.text_area(\n",
        "        \"question_input_area\", # ìœ„ì ¯ì„ êµ¬ë¶„í•˜ê¸° ìœ„í•œ ê³ ìœ  í‚¤\n",
        "        height=100,\n",
        "        placeholder=\"ì—¬ê¸°ì— ë¬¼ìŒ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”\",\n",
        "        label_visibility=\"collapsed\"\n",
        "    )\n",
        "\n",
        "    if st.button(\"ë‹µë³€ ìƒì„±í•˜ê¸°\"):\n",
        "        # (ì´í•˜ ë¡œì§ì€ ì´ì „ê³¼ ë™ì¼)\n",
        "        if problem_context and specific_question:\n",
        "            # ë‘ ì…ë ¥ ë‚´ìš©ì„ í•©ì³ì„œ í•˜ë‚˜ì˜ ì§ˆë¬¸ìœ¼ë¡œ êµ¬ì„±\n",
        "            full_query = f\"ë¬¸ì œ: {problem_context}\\n\\në¬¼ìŒ: {specific_question}\"\n",
        "\n",
        "            with st.spinner('AIê°€ ê°ì‚¬ ê¸°ì¤€ì„œë¥¼ ê²€í† í•˜ë©° ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...'):\n",
        "                response = rag_chain.invoke(full_query)\n",
        "\n",
        "                # ëŒ€í™” ê¸°ë¡ì— ì§ˆë¬¸, ë‹µë³€, ì°¸ê³ ìë£Œ, ì‹œê°„ ì •ë³´ ëª¨ë‘ ì €ì¥\n",
        "                st.session_state.history.append({\n",
        "                    'query': full_query,\n",
        "                    'result': response['result'],\n",
        "                    'sources': response['source_documents'],\n",
        "                    'timestamp': datetime.datetime.now()\n",
        "                })\n",
        "        else:\n",
        "            st.warning(\"ë¬¸ì œì™€ ë¬¼ìŒ ë‚´ìš©ì„ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”!\")\n",
        "\n",
        "    # --- ìµœì‹  ë‹µë³€ì„ ë©”ì¸ í™”ë©´ì— ì¦‰ì‹œ í‘œì‹œ ---\n",
        "if st.session_state.history:\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # 1. ë©”ì¸ í—¤ë”ë¥¼ \"## ë‹µë³€\"ìœ¼ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.\n",
        "    st.markdown(\"## ë‹µë³€\")\n",
        "    latest_item = st.session_state.history[-1]\n",
        "\n",
        "    # 2. AI ë‹µë³€ ë¬¸ìì—´ì„ ë¶„ë¦¬í•˜ëŠ” ë¡œì§ì€ ê·¸ëŒ€ë¡œ ë‘¡ë‹ˆë‹¤.\n",
        "    response_text = latest_item['result']\n",
        "    parts = response_text.split(\"### íŒë‹¨ ê·¼ê±°:\")\n",
        "\n",
        "    answer_part = parts[0].replace(\"### ì •ë‹µ:\", \"\").strip()\n",
        "\n",
        "    # 3. st.success() ëŒ€ì‹  f-stringì„ ì´ìš©í•œ st.markdown()ìœ¼ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.\n",
        "    #    ì´ë ‡ê²Œ í•˜ë©´ 'ì •ë‹µ:' ë ˆì´ë¸”ê³¼ ë‚´ìš©ì´ í•¨ê»˜ í‘œì‹œë©ë‹ˆë‹¤.\n",
        "    st.markdown(f\"**ì •ë‹µ:** {answer_part}\")\n",
        "\n",
        "    if len(parts) > 1:\n",
        "        reason_part = parts[1].strip()\n",
        "        # 4. st.expander() ëŒ€ì‹  f-stringì„ ì´ìš©í•œ st.markdown()ìœ¼ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.\n",
        "        st.markdown(f\"**íŒë‹¨ ê·¼ê±°:** {reason_part}\")\n",
        "\n",
        "        # ì°¸ê³  ìë£Œ í‘œì‹œ\n",
        "        with st.expander(\"ì°¸ê³  ìë£Œ (AIê°€ ê²€í† í•œ ì›ë¬¸)\"):\n",
        "            for doc in latest_item['sources']:\n",
        "                st.markdown(f\"**ğŸ“– {doc.metadata.get('source', 'ì¶œì²˜ ì—†ìŒ')}**\")\n",
        "                st.markdown(f\"> {doc.page_content}\")\n",
        "                st.markdown(\"---\")\n",
        "\n",
        "except Exception as e:\n",
        "    st.error(f\"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\")\n",
        "\n",
        "\n",
        "# --- 'ëŒ€í™” ê¸°ë¡ ë³´ê¸°'ë¥¼ ëˆŒë €ì„ ë•Œë§Œ ì „ì²´ ê¸°ë¡ í‘œì‹œ ---\n",
        "if st.session_state.show_history:\n",
        "    st.markdown(\"---\")\n",
        "    st.header(\"ìµœê·¼ ì§ˆë¬¸ê³¼ ë‹µë³€\")\n",
        "\n",
        "    if not st.session_state.history:\n",
        "        st.info(\"í‘œì‹œí•  ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "    else:\n",
        "        # ì˜¤ë˜ëœ ìˆœì„œëŒ€ë¡œ ì •ë ¬í•˜ì—¬ í‘œì‹œ\n",
        "        for item in st.session_state.history:\n",
        "            query_time = item['timestamp'].strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            with st.container():\n",
        "                st.markdown(f\"<small style='color:grey;'>ì§ˆë¬¸ ì‹œê°: {query_time}</small>\", unsafe_allow_html=True)\n",
        "                # ì§ˆë¬¸ ë¸”ë¡\n",
        "                with st.chat_message(\"user\", avatar=\"â“\"):\n",
        "                    st.text(item['query'])\n",
        "                # ë‹µë³€ ë¸”ë¡\n",
        "                with st.chat_message(\"assistant\", avatar=\"ğŸ¤–\"):\n",
        "                    # 'ì •ë‹µ'ê³¼ 'íŒë‹¨ ê·¼ê±°'ë¥¼ ë¶„ë¦¬í•´ì„œ êµ¬ì¡°ì ìœ¼ë¡œ ë³´ì—¬ì¤Œ\n",
        "                    parts = item['result'].split(\"### íŒë‹¨ ê·¼ê±°:\")\n",
        "                    if len(parts) == 2:\n",
        "                        answer_part = parts[0].replace(\"### ì •ë‹µ:\", \"\").strip()\n",
        "                        reason_part = parts[1].strip()\n",
        "                        st.markdown(\"**ì •ë‹µ**\")\n",
        "                        st.markdown(answer_part)\n",
        "                        st.markdown(\"**íŒë‹¨ ê·¼ê±°**\")\n",
        "                        st.markdown(reason_part)\n",
        "                    else: # ë¶„ë¦¬ ì‹¤íŒ¨ ì‹œ ì „ì²´ ê²°ê³¼ í‘œì‹œ\n",
        "                        st.markdown(item['result'])\n",
        "                st.markdown(\"---\") # ì„¸íŠ¸ë³„ êµ¬ë¶„ì„ "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xXWQ91alT8M",
        "outputId": "e7c76d23-8c3f-4a9e-dc3d-1b87146a88fc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Streamlit ì•± ì‹¤í–‰"
      ],
      "metadata": {
        "id": "kgPH-xr4ol-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "from google.colab import userdata\n",
        "\n",
        "# ngrok ì¸ì¦ í† í° ì„¤ì •\n",
        "try:\n",
        "    NGROK_AUTH_TOKEN = userdata.get('NGROK_AUTH_TOKEN')\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "    print(\"Ngrok ì¸ì¦ í† í° ì„¤ì • ì™„ë£Œ.\")\n",
        "except Exception as e:\n",
        "    print(f\"Ngrok ì¸ì¦ í† í° ì„¤ì • ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "# ì•± ì‹¤í–‰ ë° ì ‘ì† ì£¼ì†Œ ìƒì„±\n",
        "try:\n",
        "    ngrok.kill()\n",
        "    public_url = ngrok.connect(8501)\n",
        "    print(f\"ğŸ‰ Streamlit ì•±ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤! ì•„ë˜ ì£¼ì†Œë¡œ ì ‘ì†í•˜ì„¸ìš”: \\n{public_url}\")\n",
        "    !streamlit run app.py &>/dev/null&\n",
        "except Exception as e:\n",
        "    print(f\"Streamlit ì•± ì‹¤í–‰ ì‹¤íŒ¨: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5aEMmReomzX",
        "outputId": "a2699012-617b-40c7-a500-260aca0798b9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pyngrok.process.ngrok:t=2025-07-28T18:41:13+0000 lvl=eror msg=\"failed to reconnect session\" obj=tunnels.session err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-07-28T18:41:13+0000 lvl=eror msg=\"session closing\" obj=tunnels.session err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ngrok ì¸ì¦ í† í° ì„¤ì • ì™„ë£Œ.\n",
            "Streamlit ì•± ì‹¤í–‰ ì‹¤íŒ¨: The ngrok process errored on start: authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n.\n"
          ]
        }
      ]
    }
  ]
}