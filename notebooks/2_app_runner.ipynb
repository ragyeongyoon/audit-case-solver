{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KrkA_QqioZro"
   },
   "source": [
    "라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38801,
     "status": "ok",
     "timestamp": 1753763540668,
     "user": {
      "displayName": "Ragyeong Yoon",
      "userId": "15015126247313668563"
     },
     "user_tz": -540
    },
    "id": "A0NXVgjilF5z",
    "outputId": "abb9f155-b4bd-4648-f722-8f097ebd4a7d"
   },
   "outputs": [],
   "source": [
    "# Streamlit, LangChain 등 앱 실행에 필요한 라이브러리 설치\n",
    "!pip install -qU streamlit pyngrok langchain-core langchain langchain_openai langchain_community tiktoken faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8f_DrsUoddH"
   },
   "source": [
    "기본 설정 (API 키 및 드라이브 연결)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 로컬 환경: .env 파일에서 키를 로드합니다.\n",
      "API 키 로드 성공!\n",
      "✅ Streamlit용 secrets.toml 파일 생성이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "my_openai_key = None\n",
    "my_ngrok_token = None\n",
    "my_hf_token = None\n",
    "VECTOR_STORE_DIR = None # 데이터 경로 변수도 추가\n",
    "\n",
    "if IS_COLAB:\n",
    "    # Colab 환경일 경우: Secrets 기능에서 키를 가져옵니다.\n",
    "    print(\"✅ Colab 환경: Secrets에서 키를 로드합니다.\")\n",
    "    my_openai_key = userdata.get('OPENAI_API_KEY')\n",
    "    my_ngrok_token = userdata.get('NGROK_AUTH_TOKEN')\n",
    "    my_hf_token = userdata.get('HUGGINGFACEHUB_API_TOKEN')\n",
    "else:\n",
    "    # 로컬 환경일 경우: .env 파일에서 키를 가져옵니다.\n",
    "    print(\"✅ 로컬 환경: .env 파일에서 키를 로드합니다.\")\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv() # .env 파일의 내용을 환경 변수로 로드\n",
    "    my_openai_key = os.getenv('OPENAI_API_KEY')\n",
    "    my_ngrok_token = os.getenv('NGROK_AUTH_TOKEN')\n",
    "    my_hf_token = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
    "\n",
    "if my_openai_key:\n",
    "    print(\"API 키 로드 성공!\")\n",
    "\n",
    "    # .streamlit 폴더 생성 후 secrets.toml 파일 작성\n",
    "    os.makedirs(\".streamlit\", exist_ok=True)\n",
    "    with open(\".streamlit/secrets.toml\", \"w\") as f:\n",
    "        f.write(f'OPENAI_API_KEY = \"{my_openai_key}\"')\n",
    "    print(\"✅ Streamlit용 secrets.toml 파일 생성이 완료되었습니다.\")\n",
    "    \n",
    "else:\n",
    "    # 키 로드에 실패했을 경우\n",
    "    print(\"🚨 API 키 로드 실패! Colab Secrets 또는 .env 파일을 확인해주세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XELdkvLPlRvU"
   },
   "source": [
    " Streamlit 앱 코드 작성 (app.py 파일 생성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1753730097473,
     "user": {
      "displayName": "Ragyeong Yoon",
      "userId": "15015126247313668563"
     },
     "user_tz": -540
    },
    "id": "5xXWQ91alT8M",
    "outputId": "32925f9f-6bf6-4a9a-cd36-5d8be16531c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/app.py\n",
    "\n",
    "import streamlit as st\n",
    "import os\n",
    "import datetime\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# --- 1. API 키 설정 ---\n",
    "try:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = st.secrets[\"OPENAI_API_KEY\"]\n",
    "except KeyError:\n",
    "    st.error(\"OpenAI API 키가 설정되지 않았습니다. .streamlit/secrets.toml 파일이 올바르게 생성되었는지 확인해주세요.\")\n",
    "    st.stop()\n",
    "\n",
    "# --- 2. RAG 체인 로딩 함수 (캐시 사용) ---\n",
    "@st.cache_resource\n",
    "def load_rag_chain():\n",
    "    VECTOR_STORE_DIR = 'data/03_vector_store'\n",
    "    embeddings_model = OpenAIEmbeddings()\n",
    "    vectorstore = FAISS.load_local(\n",
    "        VECTOR_STORE_DIR,\n",
    "        embeddings_model,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    prompt_template = \"\"\"\n",
    "    <지시문>\n",
    "    당신은 회계감사 전문가입니다.\n",
    "    <Context>와 <질문>을 바탕으로 답변을 생성하세요.\n",
    "    답변은 반드시 아래 <답변형식>을 따라야 하며, '답변 근거란', '관련 교재 내용' 같은 문구는 절대 출력하면 안 됩니다.\n",
    "    '###' 기호는 사용하지 마세요.\n",
    "    한국어로 작성해 주세요\n",
    "    </지시문>\n",
    "\n",
    "    <답변형식>\n",
    "    ### 정답:\n",
    "    질문에 대한 명확한 결론을 내립니다. 물어보는 것에 대해 짧게 대답합니다.\n",
    "    여부를 물었을 때는 O/X로 대답합니다.\n",
    "    적절한가? 하고 물었을 때는 예, 아니오로 대답합니다.\n",
    "    잘못된 감사절차를 물었을 때는 본문에서 잘못된 감사절차 내용을 찾습니다.\n",
    "    수행하여야 할 절차를 물었을 때는 구체적인 사례보다는 context에서 절차 관련된 언급이 있을 경우 기준서를 최대한 준용합니다.\n",
    "    몇 가지를 물어보는지 파악하고 질문에 맞는 답안을 구성합니다. (2가지를 물었을 경우 2가지로 대답합니다. 첫째 사항/절차(물음에서 물어본것)는, 둘째 사항/절차(물음에서 물어본것)는, 이런 식으로 대답합니다.)\n",
    "\n",
    "    ### 판단 근거:\n",
    "    서술형으로 작성합니다.\n",
    "    구체적인 기준이나 문구를 인용합니다\n",
    "    최대한 감사기준서나 절차는 제공된 context의 용어와 표현을 그대로 사용합니다.\n",
    "    사례에서 제공된 문제점을 지적할 수 있습니다.\n",
    "    다만, context의 회계감사기준, 윤리기준 등 다양한 내용을 근거로 위배된 부분이 있는지 파악합니다.\n",
    "    제공된 질문에서 잘못된 부분을, context를 근거로 평가해야 합니다.\n",
    "    당신은 30년 이상의 숙련된 회계사로, 모든 회계감사기준을 명백히 이해하고 있습니다.\n",
    "    당신에게 제시된 질문의 text에서 감사절차가 적절/부적절한지 판단한 이유를 근거를 들어 말해야 합니다.\n",
    "\n",
    "    ---\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question:\n",
    "    {question}\n",
    "\n",
    "    Answer(Korean):\n",
    "    \"\"\"\n",
    "    PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "    rag_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm, chain_type=\"stuff\", retriever=vectorstore.as_retriever(search_kwargs={'k': 5}),\n",
    "        chain_type_kwargs={\"prompt\": PROMPT}, return_source_documents=True\n",
    "    )\n",
    "    return rag_chain\n",
    "\n",
    "# --- 3. 대화 내용을 HTML로 변환하는 함수 ---\n",
    "def generate_html(history):\n",
    "    timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    html_content = f\"\"\"\n",
    "    <!DOCTYPE html><html><head><title>회계감사 AI 대화 기록</title>\n",
    "    <style>\n",
    "        body {{ font-family: sans-serif; line-height: 1.6; padding: 20px; }}\n",
    "        .container {{ max-width: 800px; margin: auto; border: 1px solid #ddd; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}\n",
    "        .qa-pair {{ border-bottom: 2px solid #eee; padding-bottom: 20px; margin-bottom: 20px; }}\n",
    "        .question-block {{ background-color: #e1f5fe; padding: 15px; border-radius: 8px; margin-bottom: 10px; border-left: 5px solid #0288d1; }}\n",
    "        .answer-block {{ background-color: #f1f8e9; padding: 15px; border-radius: 8px; margin-bottom: 20px; border-left: 5px solid #7cb342;}}\n",
    "        h1, h2, h3 {{ color: #0277bd; }}\n",
    "        h1 {{ text-align: center; }}\n",
    "        .timestamp {{ text-align: right; color: #757575; font-size: 0.9em; }}\n",
    "        .save-timestamp {{ text-align: center; color: #757575; margin-bottom: 20px; }}\n",
    "        pre {{ white-space: pre-wrap; word-wrap: break-word; font-size: 14px; }}\n",
    "    </style></head><body><div class=\"container\">\n",
    "        <h1>회계감사 AI 대화 기록</h1>\n",
    "        <p class=\"save-timestamp\">저장 시각: {timestamp}</p>\n",
    "    \"\"\"\n",
    "    for item in history:\n",
    "        # Markdown을 HTML 줄바꿈으로 변경\n",
    "        formatted_result = item['result'].replace('\\n', '<br>')\n",
    "        # 질문 시간을 HTML에 추가\n",
    "        query_timestamp = item['timestamp'].strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        html_content += f\"\"\"\n",
    "        <div class=\"qa-pair\">\n",
    "            <p class=\"timestamp\">질문 시각: {query_timestamp}</p>\n",
    "            <div class='question-block'>\n",
    "                <h3>질문</h3>\n",
    "                <pre>{item['query']}</pre>\n",
    "            </div>\n",
    "            <div class='answer-block'>\n",
    "                <h3>AI 답변</h3>\n",
    "                {formatted_result}\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    html_content += \"</div></body></html>\"\n",
    "    return html_content\n",
    "\n",
    "# --- 4. Streamlit 웹 UI 구성 ---\n",
    "st.set_page_config(page_title=\"회계감사 RAG AI\", layout=\"wide\")\n",
    "st.title(\"🤖 회계감사 문제풀이 AI 어시스턴트\")\n",
    "\n",
    "# --- st.session_state 초기화 ---\n",
    "# 'history': 대화 기록 저장\n",
    "# 'show_history': 대화 기록 보기/숨기기 상태 저장\n",
    "if 'history' not in st.session_state:\n",
    "    st.session_state.history = []\n",
    "if 'show_history' not in st.session_state:\n",
    "    st.session_state.show_history = False\n",
    "\n",
    "# --- 사이드바 UI ---\n",
    "with st.sidebar:\n",
    "    st.header(\"메뉴\")\n",
    "\n",
    "    # 1. 대화 기록 보기 버튼 (상태 토글)\n",
    "    if st.button(\"대화 기록 보기/숨기기\"):\n",
    "        st.session_state.show_history = not st.session_state.show_history\n",
    "\n",
    "    # 2. 대화 기록 저장 버튼\n",
    "    if st.session_state.history:\n",
    "        html_str = generate_html(st.session_state.history)\n",
    "        file_name = f\"audit_conversation_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.html\"\n",
    "        st.download_button(\n",
    "            label=\"대화 내용 HTML로 저장\",\n",
    "            data=html_str.encode('utf-8'),\n",
    "            file_name=file_name,\n",
    "            mime='text/html'\n",
    "        )\n",
    "\n",
    "    # 3. 대화 기록 초기화 버튼\n",
    "    if st.button(\"대화 기록 초기화\"):\n",
    "        st.session_state.history = []\n",
    "        st.session_state.show_history = False # 기록 초기화 시 보기 상태도 초기화\n",
    "        st.success(\"대화 기록이 초기화되었습니다.\")\n",
    "\n",
    "\n",
    "# --- 메인 화면 UI ---\n",
    "try:\n",
    "    rag_chain = load_rag_chain()\n",
    "\n",
    "    st.caption(\"회계감사 시험 문제를 입력하세요\")\n",
    "    # 입력란 2개로 분리\n",
    "    # st.markdown을 사용하여 원하는 크기의 제목을 표시합니다.\n",
    "    st.markdown(\"### 문제\")\n",
    "    # 기존 text_area의 label은 숨깁니다 (label_visibility=\"collapsed\").\n",
    "    problem_context = st.text_area(\n",
    "        \"problem_input_area\", # 위젯을 구분하기 위한 고유 키\n",
    "        height=80,\n",
    "        placeholder=\"여기에 문제 내용을 입력하세요\",\n",
    "        label_visibility=\"collapsed\"\n",
    "    )\n",
    "\n",
    "    # 두 번째 입력창도 동일하게 수정합니다.\n",
    "    st.markdown(\"### 물음\")\n",
    "    specific_question = st.text_area(\n",
    "        \"question_input_area\", # 위젯을 구분하기 위한 고유 키\n",
    "        height=300,\n",
    "        placeholder=\"여기에 물음 내용을 입력하세요\",\n",
    "        label_visibility=\"collapsed\"\n",
    "    )\n",
    "\n",
    "    if st.button(\"답변 생성하기\"):\n",
    "        # (이하 로직은 이전과 동일)\n",
    "        if problem_context and specific_question:\n",
    "            # 두 입력 내용을 합쳐서 하나의 질문으로 구성\n",
    "            full_query = f\"문제: {problem_context}\\n\\n물음: {specific_question}\"\n",
    "\n",
    "            with st.spinner('AI가 감사 기준서를 검토하며 답변을 생성 중입니다...'):\n",
    "                response = rag_chain.invoke(full_query)\n",
    "\n",
    "                # 대화 기록에 질문, 답변, 참고자료, 시간 정보 모두 저장\n",
    "                st.session_state.history.append({\n",
    "                    'query': full_query,\n",
    "                    'result': response['result'],\n",
    "                    'sources': response['source_documents'],\n",
    "                    'timestamp': datetime.datetime.now()\n",
    "                })\n",
    "        else:\n",
    "            st.warning(\"문제와 물음 내용을 모두 입력해주세요!\")\n",
    "except Exception as e:\n",
    "    st.error(f\"오류가 발생했습니다: {e}\")\n",
    "\n",
    "# --- 최신 답변을 메인 화면에 즉시 표시 ---\n",
    "if st.session_state.history:\n",
    "    st.markdown(\"---\")\n",
    "    st.markdown(\"### 답변\")\n",
    "    latest_item = st.session_state.history[-1]\n",
    "\n",
    "    response_text = latest_item['result']  # AI가 생성한 전체 텍스트\n",
    "    parts = response_text.split(\"### 판단 근거:\") # AI 답변을 '### 판단 근거:' 기준으로 분리\n",
    "    answer_part = parts[0].replace(\"### 정답:\", \"\").strip()  # '정답' 부분 텍스트 정리\n",
    "\n",
    "    st.write(answer_part)\n",
    "    st.markdown(\"---\") # 구분선\n",
    "\n",
    "    # '판단 근거'가 있는 경우\n",
    "    if len(parts) > 1:\n",
    "        reason_part = parts[1].strip()\n",
    "        # 2. [판단 근거] 헤더와 내용을 올바른 문법으로 표시\n",
    "        st.markdown(\"### **[판단 근거]**\")\n",
    "        st.write(reason_part)\n",
    "\n",
    "    # 3. 참고 자료 표시\n",
    "    with st.expander(\"📚 참고 자료 (AI가 검토한 원문)\"):\n",
    "        for doc in latest_item['sources']:\n",
    "            st.markdown(f\"**📖 {doc.metadata.get('source', '출처 없음')}**\")\n",
    "            st.markdown(f\"> {doc.page_content}\")\n",
    "            st.markdown(\"---\")\n",
    "\n",
    "\n",
    "# --- '대화 기록 보기'를 눌렀을 때만 전체 기록 표시 ---\n",
    "if st.session_state.show_history:\n",
    "    st.markdown(\"---\")\n",
    "    st.header(\"최근 질문과 답변\")\n",
    "\n",
    "    if not st.session_state.history:\n",
    "        st.info(\"표시할 대화 기록이 없습니다.\")\n",
    "    else:\n",
    "        # 오래된 순서대로 정렬하여 표시\n",
    "        for item in st.session_state.history:\n",
    "            query_time = item['timestamp'].strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            with st.container():\n",
    "                st.markdown(f\"<small style='color:grey;'>질문 시각: {query_time}</small>\", unsafe_allow_html=True)\n",
    "                # 질문 블록\n",
    "                with st.chat_message(\"user\", avatar=\"❓\"):\n",
    "                    st.text(item['query'])\n",
    "                # 답변 블록\n",
    "                with st.chat_message(\"assistant\", avatar=\"🤖\"):\n",
    "                    # '정답'과 '판단 근거'를 분리해서 구조적으로 보여줌\n",
    "                    parts = item['result'].split(\"### 판단 근거:\")\n",
    "                    if len(parts) == 2:\n",
    "                        answer_part = parts[0].replace(\"### 정답:\", \"\").strip()\n",
    "                        reason_part = parts[1].strip()\n",
    "                        st.markdown(\"**정답**\")\n",
    "                        st.markdown(answer_part)\n",
    "                        st.markdown(\"**판단 근거**\")\n",
    "                        st.markdown(reason_part)\n",
    "                    else: # 분리 실패 시 전체 결과 표시\n",
    "                        st.markdown(item['result'])\n",
    "                st.markdown(\"---\") # 세트별 구분선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kgPH-xr4ol-l"
   },
   "source": [
    "Streamlit 앱 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1008,
     "status": "ok",
     "timestamp": 1753730100259,
     "user": {
      "displayName": "Ragyeong Yoon",
      "userId": "15015126247313668563"
     },
     "user_tz": -540
    },
    "id": "f5aEMmReomzX",
    "outputId": "4151355b-8956-4379-fce7-33fb4340b514"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 로컬 환경: .env 파일에서 ngrok 토큰을 로드합니다.\n",
      "Streamlit 앱을 백그라운드에서 실행합니다...\n",
      "로컬 환경에서는 터미널에서 직접 실행해주세요.\n",
      "앱이 시작될 때까지 5초간 대기합니다...\n",
      "Ngrok 인증 토큰 설정 완료.\n",
      "🎉 Streamlit 앱이 준비되었습니다! 아래 주소로 접속하세요: \n",
      "NgrokTunnel: \"https://1b2af8f37e06.ngrok-free.app\" -> \"http://localhost:8501\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pyngrok import ngrok\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ngrok 인증 토큰 불러오기\n",
    "my_ngrok_token = None\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IS_COLAB:\n",
    "    print(\"✅ Colab 환경: Secrets에서 ngrok 토큰을 로드합니다.\")\n",
    "    from google.colab import userdata\n",
    "    my_ngrok_token = userdata.get('NGROK_AUTH_TOKEN')\n",
    "else:\n",
    "    print(\"✅ 로컬 환경: .env 파일에서 ngrok 토큰을 로드합니다.\")\n",
    "    load_dotenv()\n",
    "    my_ngrok_token = os.getenv('NGROK_AUTH_TOKEN')\n",
    "\n",
    "# Streamlit 앱을 백그라운드에서 먼저 실행\n",
    "try:\n",
    "    print(\"Streamlit 앱을 백그라운드에서 실행합니다...\")\n",
    "    if IS_COLAB:\n",
    "        !streamlit run src/app.py &>/dev/null&\n",
    "    else:\n",
    "        # 로컬에서 백그라운드 실행이 필요하다면 별도 터미널에서 실행하는 것을 권장합니다.\n",
    "        print(\"로컬 환경에서는 터미널에서 직접 실행해주세요.\")\n",
    "\n",
    "    # 앱이 시작될 때까지 잠시 대기 (예: 5초)\n",
    "    print(\"앱이 시작될 때까지 5초간 대기합니다...\")\n",
    "    time.sleep(5)\n",
    "\n",
    "# ngrok 인증 토큰 설정 (가장 중요한 부분)\n",
    "    if my_ngrok_token:\n",
    "        ngrok.set_auth_token(my_ngrok_token)\n",
    "        print(\"Ngrok 인증 토큰 설정 완료.\")\n",
    "        \n",
    "        ngrok.kill() # 기존 세션 종료\n",
    "        public_url = ngrok.connect(8501)\n",
    "        print(f\"🎉 Streamlit 앱이 준비되었습니다! 아래 주소로 접속하세요: \\n{public_url}\")\n",
    "    else:\n",
    "        print(\"🚨 Ngrok 인증 토큰을 찾을 수 없습니다.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Streamlit 앱 또는 ngrok 실행 실패: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
